import streamlit as st
from pathlib import Path
import pandas as pd
import numpy as np
import pickle
import pwlf
from model_utils import (
    clean_marginal_data,
    incremental_retrain,
    load_or_train_model,
    predict_price,
    DATA_PATH,
    MODEL_PATH,
)

st.set_page_config(page_title="", layout="wide")

st.title("CoPiLinearæ¨¡å‹æ—¥å‰ä»·æ ¼é¢„æµ‹")

MENU = st.sidebar.radio("å¯¼èˆª", ["æ–°è¾¹é™…æ•°æ®å¯¼å…¥", "æ—¥å‰ä»·æ ¼é¢„æµ‹", "æ•°æ®å±•ç¤º", "å…³äº"])

# ---------------------------------------------------------------------------
# 1. Retrain model tab
# ---------------------------------------------------------------------------
if MENU == "æ–°è¾¹é™…æ•°æ®å¯¼å…¥":
    st.subheader("ä¸Šä¼ æœ€æ–°çš„è¾¹é™…æ•°æ®")

    file = st.file_uploader("é€‰æ‹© CSV/XLSX æ–‡ä»¶", type=["csv", "xlsx"])

    n_segments = st.slider("pwlf æ‹Ÿåˆæ®µæ•°", min_value=2, max_value=8, value=3)
    iqr_factor = st.slider("IQR outlier factor (e.g. 1.5 = Tukey fence)", 0.5, 5.0, 1.5, 0.1)

    if st.button("ğŸš€ å¼€å§‹å¢é‡è®­ç»ƒ"):
        if not file:
            st.warning("è¯·å…ˆä¸Šä¼ æ–‡ä»¶")
            st.stop()
        # -------------------------------------------------------------------
        # Load & clean new data
        # -------------------------------------------------------------------
        raw_df = (
            pd.read_csv(file) if file.name.lower().endswith(".csv") else pd.read_excel(file)
        )
        st.write(f"åŸå§‹æ•°æ®: **{len(raw_df):,}**")
        cleaned_df = clean_marginal_data(raw_df.copy(), iqr_factor=iqr_factor)
        st.write(f"æ¸…ç†åçš„åŸå§‹æ•°æ®: **{len(cleaned_df):,}**")

        # -------------------------------------------------------------------
        # Incremental retraining
        # -------------------------------------------------------------------
        model, breakpoints, combined = incremental_retrain(
            cleaned_df, n_segments=n_segments
        )
        # Show **only** rows that were removed by cleaning
        removed = raw_df.loc[raw_df.index.difference(cleaned_df.index)]
        if removed.empty:
            st.success("No rows were removed as outliers or NaNs.")
        else:
            st.warning(f"Removed rows: {len(removed)}")
            st.dataframe(removed.head(20))

        # Continue pipeline with cleaned data
        model, breakpoints, combined = incremental_retrain(
            cleaned_df, n_segments=n_segments, iqr_factor=iqr_factor
        )
        st.success(
            f"æ¨¡å‹é‡æ–°è®­ç»ƒå®Œæˆï¼Œå…± **{len(combined):,}** æ¡è®°å½•ã€‚æ–­ç‚¹: {np.round(breakpoints, 4)}"
        )
        if "date" in combined.columns:
            start, end = combined["date"].min(), combined["date"].max()
            st.info(f"æ¨¡å‹è®­ç»ƒæ•°æ®åŒºé—´ï¼š**{start}** â€” **{end}**")
        # Allow download of updated model & dataset
        with open(MODEL_PATH, "rb") as f:
            st.download_button("â¬‡ï¸ ä¸‹è½½æ–°æ¨¡å‹", f, file_name="pwlf_model.pkl")
        st.download_button(
            "â¬‡ï¸ ä¸‹è½½åˆå¹¶åçš„è¾¹é™…æ•°æ® (CSV)",
            combined.to_csv(index=False),
            file_name="marginal_merged.csv",
        )

# ---------------------------------------------------------------------------
# 2. Forecast tab (implements *forecast* module)
# ---------------------------------------------------------------------------
elif MENU == "æ—¥å‰ä»·æ ¼é¢„æµ‹":
    st.subheader("æ ¹æ®è´Ÿè·ç‡é¢„æµ‹æ—¥å‰ä»·æ ¼é¢„æµ‹")
    # --- æ˜¾ç¤ºå½“å‰ marginal.csv çš„æ—¥æœŸèŒƒå›´ ---
    if DATA_PATH.exists():
        meta_df = pd.read_csv(DATA_PATH, parse_dates=["date"], usecols=["date"], nrows=100000)
        if "date" in meta_df.columns and not meta_df["date"].isna().all():
            start, end = meta_df["date"].min(), meta_df["date"].max()
            st.info(f"å½“å‰CoPiLinearæ¨¡å‹åŒ…å«æ—¥æœŸèŒƒå›´ï¼š**{start.date()}** â€” **{end.date()}**")
        else:
            st.warning("æ•°æ®æºä¸­ç¼ºå°‘å¯è§£æçš„ date åˆ—ã€‚")
    else:
        st.warning("æœªæ‰¾åˆ°æ•°æ®æºï¼Œè¯·å…ˆåœ¨ Retrain é¡µä¸Šä¼ æ•°æ®å¹¶è®­ç»ƒæ¨¡å‹ã€‚")

    model = load_or_train_model()
    if model is None:
        st.error("æœªæ‰¾åˆ°æ¨¡å‹ã€‚")
        st.stop()

    # Input options: manual values or batch file
    # mode = st.radio("Prediction mode", ["Manual input", "Batch CSV/XLSX"])

    # if mode == "Manual input":
    #     x_vals = st.text_input(
    #         "Enter one or more loadâ€‘rate values (0â€‘1) separated by commas", "0.55, 0.78, 0.93"
    #     )
    #     if st.button("Predict"):
    #         try:
    #             xs = np.array([float(v) for v in x_vals.split(",")])
    #         except ValueError:
    #             st.error("Invalid numeric input.")
    #             st.stop()
    #         preds = predict_price(model, xs)
    #         st.write(pd.DataFrame({"load_rate": xs, "predicted_price": preds}))
    #
    # else:
    file = st.file_uploader("ä¸Šä¼ é¢„æµ‹æ ‡çš„æ—¥è´Ÿè·ç‡æ•°æ® CSV/XLSX", type=["csv", "xlsx"])
    x_col = st.text_input("è´Ÿè·ç‡åˆ—åç§°", "æ—¥å‰è´Ÿè·ç‡(%)")
    if st.button("é¢„æµ‹") and file:
        df = pd.read_csv(file) if file.name.endswith(".csv") else pd.read_excel(file)
        if x_col not in df.columns:
            st.error(f"æ‰¾ä¸åˆ° '{x_col}'")
            st.stop()
        preds = predict_price(model, df[x_col].values)
        out_df = df.copy()
        out_df["æ—¥å‰é¢„æµ‹ä»·æ ¼"] = preds
        st.dataframe(out_df.head())
        st.download_button(
            "â¬‡ï¸ ä¸‹è½½é¢„æµ‹",
            out_df.to_csv(index=False).encode(),
            file_name="price_predictions.csv",
        )
        chart_df = pd.DataFrame({
            "time_slot": np.arange(2, len(preds) + 1),
            "price": preds,
        })
        st.line_chart(
            chart_df.set_index("time_slot"),
            height=300,
        )

# ---------------------------------------------------------------------------
# 3. Data Display tab
# ---------------------------------------------------------------------------
elif MENU == "æ•°æ®å±•ç¤º":
    st.subheader("CSVæ•°æ®å±•ç¤ºä¸ç­›é€‰")
    
    # Load default data
    if DATA_PATH.exists():
        st.info("æ•°æ®æ¥æº: marginal.csv")
        original_df = pd.read_csv(DATA_PATH)
    else:
        st.warning("æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ marginal.csv")
        st.stop()
    
    if original_df.empty:
        st.warning("æ•°æ®æ–‡ä»¶ä¸ºç©º")
        st.stop()
    
    # Display basic info
    st.write(f"**æ•°æ®æ€»è¡Œæ•°:** {len(original_df):,}")
    st.write(f"**æ•°æ®åˆ—æ•°:** {len(original_df.columns)}")
    
    # Create filter section
    st.subheader("ç­›é€‰æ¡ä»¶")
    
    # Create three columns for filters
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.write("**æ—¶é—´ç­›é€‰**")
        
        # Try to detect date columns
        date_columns = []
        for col in original_df.columns:
            if 'date' in col.lower() or 'æ—¥æœŸ' in col or 'æ—¶é—´' in col:
                date_columns.append(col)
        
        date_filter_enabled = False
        start_date = None
        end_date = None
        date_col = None
        
        if date_columns:
            date_col = st.selectbox("é€‰æ‹©æ—¥æœŸåˆ—", date_columns)
            
            # Convert to datetime if possible
            try:
                temp_df = original_df.copy()
                temp_df[date_col] = pd.to_datetime(temp_df[date_col])
                
                # Date range filter
                min_date = temp_df[date_col].min().date()
                max_date = temp_df[date_col].max().date()
                
                start_date = st.date_input("å¼€å§‹æ—¥æœŸ", min_date, min_value=min_date, max_value=max_date)
                end_date = st.date_input("ç»“æŸæ—¥æœŸ", max_date, min_value=min_date, max_value=max_date)
                date_filter_enabled = True
                
            except:
                st.warning(f"æ— æ³•è§£ææ—¥æœŸåˆ— '{date_col}'")
        else:
            st.info("æœªæ£€æµ‹åˆ°æ—¥æœŸåˆ—")
    
    with col2:
        st.write("**æ¡ä»¶ç­›é€‰**")
        
        # Column selection for filtering
        filter_columns = st.multiselect("é€‰æ‹©è¦ç­›é€‰çš„åˆ—", original_df.columns.tolist())
        
        filters = {}
        for col in filter_columns:
            if original_df[col].dtype in ['object', 'string']:
                # For text columns, use multiselect
                unique_values = original_df[col].dropna().unique().tolist()
                if len(unique_values) <= 50:  # Only show if not too many unique values
                    selected_values = st.multiselect(f"ç­›é€‰ {col}", unique_values, default=unique_values)
                    if selected_values != unique_values:  # Only add filter if changed
                        filters[col] = selected_values
                else:
                    # For columns with too many unique values, use text input
                    filter_text = st.text_input(f"ç­›é€‰ {col} (åŒ…å«æ–‡æœ¬)")
                    if filter_text:
                        filters[col] = filter_text
            else:
                # For numeric columns, use range slider
                try:
                    min_val = float(original_df[col].min())
                    max_val = float(original_df[col].max())
                    if min_val != max_val:
                        range_values = st.slider(
                            f"ç­›é€‰ {col} èŒƒå›´",
                            min_val, max_val, (min_val, max_val)
                        )
                        if range_values != (min_val, max_val):  # Only add filter if changed
                            filters[col] = range_values
                except:
                    pass
    
    with col3:
        st.write("**æ‰§è¡Œç­›é€‰**")
        st.write("")  # Add some spacing
        apply_filter = st.button("ğŸ” æ‰§è¡Œç­›é€‰", type="primary")
    
    # Apply filters only when button is clicked
    if apply_filter or 'filtered_df' not in st.session_state:
        df = original_df.copy()
        
        # Apply date filter
        if date_filter_enabled and date_col:
            try:
                df[date_col] = pd.to_datetime(df[date_col])
                mask = (df[date_col].dt.date >= start_date) & (df[date_col].dt.date <= end_date)
                df = df[mask]
            except:
                pass
        
        # Apply other filters
        for col, filter_value in filters.items():
            if isinstance(filter_value, list):
                if df[col].dtype in ['object', 'string']:
                    df = df[df[col].isin(filter_value)]
            elif isinstance(filter_value, str):
                df = df[df[col].astype(str).str.contains(filter_value, case=False, na=False)]
            elif isinstance(filter_value, tuple):
                df = df[(df[col] >= filter_value[0]) & (df[col] <= filter_value[1])]
        
        # Store filtered data in session state
        st.session_state.filtered_df = df
    else:
        # Use previously filtered data
        df = st.session_state.filtered_df if 'filtered_df' in st.session_state else original_df
    
    # Display filtered results
    st.subheader("ç­›é€‰ç»“æœ")
    st.write(f"**ç­›é€‰åè¡Œæ•°:** {len(df):,}")
    
    # Column selection for display
    display_columns = st.multiselect("é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—", df.columns.tolist(), default=df.columns.tolist()[:10])
    
    if display_columns:
        display_df = df[display_columns]
    else:
        display_df = df
    
    # Pagination
    rows_per_page = st.selectbox("æ¯é¡µæ˜¾ç¤ºè¡Œæ•°", [10, 25, 50, 100, 500], index=2)
    
    if len(display_df) > 0:
        total_pages = (len(display_df) - 1) // rows_per_page + 1
        page = st.selectbox("é¡µç ", range(1, total_pages + 1))
        
        start_idx = (page - 1) * rows_per_page
        end_idx = start_idx + rows_per_page
        
        st.dataframe(display_df.iloc[start_idx:end_idx], use_container_width=True)
        
        # Download filtered data
        csv = display_df.to_csv(index=False)
        st.download_button(
            "â¬‡ï¸ ä¸‹è½½ç­›é€‰åçš„æ•°æ®",
            csv,
            file_name="filtered_data.csv",
            mime="text/csv"
        )
        
        # Basic statistics for numeric columns
        numeric_cols = display_df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            st.subheader("æ•°å€¼åˆ—ç»Ÿè®¡")
            st.dataframe(display_df[numeric_cols].describe())
            
            # Simple charts
            if len(numeric_cols) >= 1:
                st.subheader("æ•°æ®å¯è§†åŒ–")
                chart_col = st.selectbox("é€‰æ‹©è¦ç»˜åˆ¶çš„æ•°å€¼åˆ—", numeric_cols)
                chart_type = st.selectbox("å›¾è¡¨ç±»å‹", ["æŠ˜çº¿å›¾", "æŸ±çŠ¶å›¾", "ç›´æ–¹å›¾"])
                
                # Try to find a suitable x-axis column (prioritize time_slot, then date)
                x_axis_col = None
                if 'time_slot' in display_df.columns:
                    x_axis_col = 'time_slot'
                elif date_col and date_col in display_df.columns:
                    x_axis_col = date_col
                
                if chart_type == "æŠ˜çº¿å›¾":
                    if x_axis_col:
                        # Create a proper chart with time_slot or date on x-axis
                        chart_df = display_df[[x_axis_col, chart_col]].copy().dropna()
                        if x_axis_col == date_col:
                            try:
                                chart_df[x_axis_col] = pd.to_datetime(chart_df[x_axis_col])
                            except:
                                pass
                        # Sort by x-axis for proper time series display
                        chart_df = chart_df.sort_values(x_axis_col)
                        st.line_chart(chart_df.set_index(x_axis_col))
                    else:
                        # Use row index as x-axis
                        chart_df = display_df[chart_col].reset_index()
                        chart_df.columns = ['åºå·', chart_col]
                        st.line_chart(chart_df.set_index('åºå·'))
                        
                elif chart_type == "æŸ±çŠ¶å›¾":
                    if x_axis_col and len(display_df) <= 100:  # Limit for readability
                        chart_df = display_df[[x_axis_col, chart_col]].copy().dropna()
                        if x_axis_col == date_col:
                            try:
                                chart_df[x_axis_col] = pd.to_datetime(chart_df[x_axis_col])
                            except:
                                pass
                        # Sort by x-axis for proper time series display
                        chart_df = chart_df.sort_values(x_axis_col)
                        st.bar_chart(chart_df.set_index(x_axis_col))
                    else:
                        # Use row index as x-axis, limit to first 50 rows for readability
                        limited_df = display_df[chart_col].head(50).reset_index()
                        limited_df.columns = ['åºå·', chart_col]
                        st.bar_chart(limited_df.set_index('åºå·'))
                        if len(display_df) > 50:
                            st.info("ä¸ºäº†å›¾è¡¨å¯è¯»æ€§ï¼Œä»…æ˜¾ç¤ºå‰50è¡Œæ•°æ®")
                            
                elif chart_type == "ç›´æ–¹å›¾":
                    # Show distribution of values
                    value_counts = display_df[chart_col].value_counts().head(20)
                    st.bar_chart(value_counts)
                
                # Show which column is being used as x-axis
                if x_axis_col:
                    st.info(f"æ¨ªè½´ä½¿ç”¨åˆ—: {x_axis_col}")
    else:
        st.warning("æ²¡æœ‰æ•°æ®å¯æ˜¾ç¤º")

# ---------------------------------------------------------------------------
# 4. About tab
# ---------------------------------------------------------------------------
else:
    st.markdown(
        """
### About this tool
This Streamlit application wraps two onceâ€‘separate commandâ€‘line pipelines:
1. **reappropriation** â€“ incremental cleaning & retraining of a pieceâ€‘wise linear (pwlf) model.
2. **forecast** â€“ price prediction from new loadâ€‘rate values.

The entire workflow is now pointâ€‘andâ€‘click but conserves the underlying Python logic (see `model_utils.py`).
        """
    )

# ---------------------------------------------------------------------------
# End of app.py
# ---------------------------------------------------------------------------
